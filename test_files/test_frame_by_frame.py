#!/usr/bin/env python3
"""
é€å¸§æ£€æµ‹å¹¶è¾“å‡ºå’Œä½ è¦æ±‚ç›¸åŒçš„æ ¼å¼
"""

import cv2
import time
from ultralytics import YOLO

def test_frame_by_frame_detection():
    """é€å¸§æ£€æµ‹å¹¶è¾“å‡ºè¯¦ç»†ä¿¡æ¯"""
    
    video_path = 'input_videos/08fd33_4.mp4'
    model = YOLO('yolo11n.pt')
    
    # æ‰“å¼€è§†é¢‘
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"âŒ æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")
        return
    
    # è·å–è§†é¢‘ä¿¡æ¯
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    
    print(f"ğŸ“¹ è§†é¢‘ä¿¡æ¯: {width}x{height}, {fps}fps, {total_frames}å¸§")
    print(f"ğŸ” å¼€å§‹é€å¸§æ£€æµ‹...")
    print()
    
    frame_count = 0
    
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        
        frame_count += 1
        
        # è®°å½•å¼€å§‹æ—¶é—´
        start_time = time.time()
        
        # è¿›è¡Œæ£€æµ‹
        results = model.predict(frame, conf=0.3, verbose=False)
        
        # è®¡ç®—å¤„ç†æ—¶é—´
        processing_time = (time.time() - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
        
        # ç»Ÿè®¡æ£€æµ‹ç»“æœ
        detection_summary = []
        
        if results and len(results) > 0:
            result = results[0]
            if result.boxes is not None:
                # ç»Ÿè®¡å„ç±»åˆ«çš„æ•°é‡
                class_counts = {}
                for box in result.boxes:
                    class_id = int(box.cls.item())
                    class_name = model.names.get(class_id, f'class_{class_id}')
                    
                    if class_name in class_counts:
                        class_counts[class_name] += 1
                    else:
                        class_counts[class_name] = 1
                
                # æŒ‰ç…§YOLOè¾“å‡ºæ ¼å¼æ’åºå’Œæ ¼å¼åŒ–
                for class_name, count in sorted(class_counts.items()):
                    if class_name == 'person':
                        detection_summary.insert(0, f"{count} {class_name}s")  # personsæ”¾åœ¨æœ€å‰é¢
                    elif class_name == 'sports ball':
                        detection_summary.append(f"{count} sports ball")
                    else:
                        detection_summary.append(f"{count} {class_name}")
        
        # æ„å»ºè¾“å‡ºå­—ç¬¦ä¸² - å®Œå…¨æ¨¡æ‹Ÿä½ è¦æ±‚çš„æ ¼å¼
        detection_str = ", ".join(detection_summary) if detection_summary else ""
        if detection_str:
            detection_str = " " + detection_str + ","
        
        # è¾“å‡ºæ ¼å¼å®Œå…¨åŒ¹é…ä½ çš„è¦æ±‚
        output_resolution = f"{height}x{width}"  # æ³¨æ„ï¼šYOLOè¾“å‡ºæ˜¯é«˜xå®½
        print(f"video 1/1 (frame {frame_count}/{total_frames}) {video_path}: {output_resolution}{detection_str} {processing_time:.1f}ms")
        
        # å¯é€‰ï¼šåªå¤„ç†ä¸€éƒ¨åˆ†å¸§æ¥å¿«é€Ÿæµ‹è¯•
        # if frame_count >= 200:  # åªå¤„ç†å‰200å¸§
        #     break
    
    cap.release()
    print(f"\nâœ… å¤„ç†å®Œæˆï¼Œå…±{frame_count}å¸§")

def test_specific_range(start_frame=140, end_frame=165):
    """æµ‹è¯•ç‰¹å®šå¸§èŒƒå›´ï¼Œæ¨¡æ‹Ÿä½ æä¾›çš„è¾“å‡º"""
    
    video_path = 'input_videos/08fd33_4.mp4'
    model = YOLO('yolo11n.pt')
    
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"âŒ æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")
        return
    
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    
    print(f"ğŸ¯ æµ‹è¯•å¸§{start_frame}-{end_frame}ï¼Œæ¨¡æ‹Ÿä½ çš„è¾“å‡ºæ ¼å¼:")
    print()
    
    # è·³åˆ°èµ·å§‹å¸§
    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame - 1)
    
    for frame_num in range(start_frame, min(end_frame + 1, total_frames + 1)):
        ret, frame = cap.read()
        if not ret:
            break
        
        start_time = time.time()
        results = model.predict(frame, conf=0.3, verbose=False)
        processing_time = (time.time() - start_time) * 1000
        
        # ç»Ÿè®¡æ£€æµ‹ç»“æœ
        detection_summary = []
        
        if results and len(results) > 0:
            result = results[0]
            if result.boxes is not None:
                class_counts = {}
                for box in result.boxes:
                    class_id = int(box.cls.item())
                    class_name = model.names.get(class_id, f'class_{class_id}')
                    
                    if class_name in class_counts:
                        class_counts[class_name] += 1
                    else:
                        class_counts[class_name] = 1
                
                # æ ¼å¼åŒ–è¾“å‡º
                for class_name, count in sorted(class_counts.items()):
                    if class_name == 'person':
                        detection_summary.insert(0, f"{count} {class_name}s")
                    elif class_name == 'sports ball':
                        detection_summary.append(f"{count} sports ball")
                    else:
                        detection_summary.append(f"{count} {class_name}")
        
        detection_str = ", ".join(detection_summary) if detection_summary else ""
        if detection_str:
            detection_str = " " + detection_str + ","
        
        output_resolution = f"{height}x{width}"
        print(f"video 1/1 (frame {frame_num}/{total_frames}) {video_path}: {output_resolution}{detection_str} {processing_time:.1f}ms")
    
    cap.release()

if __name__ == "__main__":
    # é€‰æ‹©è¿è¡Œå“ªä¸ªæµ‹è¯•
    print("è¯·é€‰æ‹©:")
    print("1. æµ‹è¯•ç‰¹å®šå¸§èŒƒå›´(141-164) - å¿«é€ŸéªŒè¯æ ¼å¼")
    print("2. å®Œæ•´è§†é¢‘é€å¸§æ£€æµ‹ - å®Œæ•´æµ‹è¯•")
    
    choice = input("è¾“å…¥é€‰æ‹© (1 æˆ– 2): ").strip()
    
    if choice == "1":
        test_specific_range(141, 164)
    elif choice == "2":
        test_frame_by_frame_detection()
    else:
        print("é»˜è®¤è¿è¡Œç‰¹å®šå¸§èŒƒå›´æµ‹è¯•...")
        test_specific_range(141, 164)